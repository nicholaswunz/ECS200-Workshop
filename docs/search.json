[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ECS200 - Research Methods in Ecology",
    "section": "",
    "text": "Welcome\nWorkshop materials in the github repository ECS200.\nThe ECS200 - Research Methods in Ecology workshops will go through the steps of a typical data science project that looks something like Figure 1.\nFirst, you must import (week 1) your data into R. This usually means loading data stored in a file, database, or web application programming interface (API) into a data frame in R. If you can‚Äôt get your data into R, you can‚Äôt do any data science with it!\nOnce your data is imported, it‚Äôs a good idea to tidy (week 2) it. Tidying means putting it into a consistent format where each column is a variable and each row is an observation. This alignment between the structure and meaning of the data makes analysis far easier. Tidy data lets you focus on answering questions rather than reformatting for each new task.\nNext, you‚Äôll often transform (week 2) your data. This might include filtering for specific observations (e.g.¬†animals from one site or data from the past year), creating new variables (e.g.¬†calculating speed from distance and time), or summarising patterns (e.g.¬†counts or averages). Tidying and transforming are often called wrangling, because getting data into a usable form can feel like a struggle!\nOnce you have tidy, relevant data, you‚Äôll typically turn to two main tools: visualisation and modelling. These are complementary, and most analyses move back and forth between them.\nThe final step in data science is communication (visualisation and model weeks). Even the best models or visuals are useless unless you can clearly explain your findings to others. Effective communication is critical.\nSurrounding all these activities is programming. You‚Äôll use code throughout every step of a data science project. You don‚Äôt need to be a programming expert, but improving your coding skills pays off‚Äîit helps you automate tasks and solve problems more efficiently.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#learning-objectives-of-the-unit",
    "href": "index.html#learning-objectives-of-the-unit",
    "title": "ECS200 - Research Methods in Ecology",
    "section": "Learning Objectives of the Unit",
    "text": "Learning Objectives of the Unit\nAt the end of the unit, students should be able to:\n\nDesign ecological research using appropriate sampling strategies and analytical methods.\nApply appropriate statistical methods to test ecological hypotheses.\nApply R programming to process, analyse, and visualise ecological datasets to professional standards.\nCritically evaluate the strengths and limitations of research designs under different ecological conditions.\nCommunicate the findings of ecological research to professional standards.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "week1_getting_started.html",
    "href": "week1_getting_started.html",
    "title": "1¬† Quality Check",
    "section": "",
    "text": "Before we start\nWeek 1 - Quality checks and data exploration\nIn this first workshop, we‚Äôll introduce you to R, RStudio, and the basics of coding. You‚Äôll be writing your first lines of R code and importing data today!\nThis step can be skipped if you have R and Rstudio already downloaded and installed.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week1_getting_started.html#for-the-adventurous-folks",
    "href": "week1_getting_started.html#for-the-adventurous-folks",
    "title": "1¬† Quality Check",
    "section": "For the adventurous folks",
    "text": "For the adventurous folks\nFor those comfortable with R and coding and would like an additional challenge. Here is a task for you before the next week.\n\nCreate a vector tree_heights with 100 numeric values between 0-50 using the R random number generator.\nFind the quartile range of the from the tree_heightsvector.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week1_getting_started.html#background-reading",
    "href": "week1_getting_started.html#background-reading",
    "title": "1¬† Quality Check",
    "section": "Background reading",
    "text": "Background reading\nHow do we know the data is ready for analysis? Before we do any analysis, we need to check the raw data for the following:\n\nCheck data structure and types: Use str() and summary() to ensure each column is the correct type (numeric, factor, character, etc.) and matches your expectations. e.g., Convert relevant character columns to factors for categorical analysis.\nInspect for missing values: Use colSums(is.na() or visual tools (e.g., naniar::gg_miss_var() or visdat_viz_dat()) to identify missing data and decide how to handle it.\nCheck for duplicates: Ensure there are no unintended duplicate rows or IDs.\nValidate categorical variables: Confirm that categories are consistent and correctly formatted (e.g., all lower case, no extra spaces).\nScan for outliers or impossible values: Look for values outside expected ranges (e.g., negative stem lengths, impossible dates).\nReview column names: Ensure column names are meaningful, have no spaces or special characters, and are consistent.\nPreview the data: Use plotting functions to visually inspect the data for obvious issues.\nCheck for extra rows or columns: Sometimes, files have summary rows, notes, or empty columns that should be removed.\n\nThese steps help ensure your data is reliable, interpretable, and suitable for statistical analysis. Importantly, it makes you a trustworthy researcher!",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week1_getting_started.html#initial-check",
    "href": "week1_getting_started.html#initial-check",
    "title": "1¬† Quality Check",
    "section": "1.1. Initial check",
    "text": "1.1. Initial check\nThis helps you spot if variables are coded incorrectly (e.g., numbers as characters or vice versa), which could be due to the researcher error before inporting the data. Some example mistakes include:\n\nIncorrect data types: Numeric columns may be read as character (text) if there are unexpected symbols, missing values coded inconsistently, or formatting issues (e.g. a column meant to be numbers may contain text or empty strings, causing R to treat it as character instead of numeric).\nInconsistent coding: Categorical variables may be inconsistently labeled (e.g., ‚ÄúMale‚Äù, ‚Äúmale‚Äù, ‚ÄúM‚Äù), leading to multiple categories that should be merged.\nHeader issues: Sometimes, the header row is missing or duplicated, or extra non-data rows are included at the top or bottom of the file.\nEncoding problems: Special characters (e.g., accents, non-English letters) may not display correctly if the file encoding is not specified or mismatched.\nTrailing spaces: Spaces at the start or end of strings can create unexpected categories or prevent proper matching.\n\n\nFor small datasets (like in this workshop) it is easier to make fixes directly from Excel and import the new .csv file. As before, we will check the data here first with the str() function.\n\n# Check the structure of your data\nstr(plant_data)\n\n# Get a summary of all variables\nsummary(plant_data)\n\n\nExercise (5 min)\nüß™ Find the incorrect class in this dataset\nI have created an example dataset called fake_data with three things wrong with it. Find the three issues in this dataset.\n\nfake_data &lt;- data.frame(\n  site = c(\"A\", \"B\", \"C\", \"A\", \"B\", \"A\", \"B\", \"C\", \"a\", \"B\", \"A\", \"B\", \"A\", \"B\", \"C\", \"C\", \"B\", \"A\", \"A\", \"C\", \"B\", \"C\", \"C\", \"A\", \"A\", \"A\", \"A\", \"B\", \"C\", \"C\", \"C\"),\n  species_1 = c(7, 25, 30, 50, 38, 13, 5, 31, 34, 22, 41, 25, 22, 37, 39, 13, 45, 10, 40, 7, 28, 36, 19, 2, 12, 5, 16, 38, 27, 44, 44),\n  species_2 = c(9.3, 8.6, 0.8 , 7.5, 9 , 9.1, 4.3, 8.6, 0.1, 7.8, 1.2, 6.2, 0.4, 0.4, 7.4, 1.9, 8.3, 7.8, 2.9, 9.3, 9.1, 2.3, 6.3, 8.5, 6.5, 6.6, \"1,7\", 1.8, 8.4, 4.7, 4.7),\n  species_3 = c(190, 160, 70, 430, 310, 99, 530, 420, 371, 357, 198, 171, 463, 124, 254, 484, 435, 409, 122, 305, 410, 162, 473, 200, 401, 273, 421, 419, 293, 487, 487),\n  species_4 = c(2, 0, 4, 8, 6.7, 3, 7.2, 4.3, 2, NA, 10, 10, 6, 4, 8, 1.7, 1, 0, NA, 4, 6, 8.2, 10, 6, 2, 5, 10, 7, NA, NA, NA)\n)\n\nWhat are the identified issues?\n\n\nShow answer\n\n\nsite should be factor, not character\nspecies_2 should be numeric, not character\nspecies_4 has 5 NA‚Äôs",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week1_getting_started.html#identify-missing-values",
    "href": "week1_getting_started.html#identify-missing-values",
    "title": "1¬† Quality Check",
    "section": "1.2. Identify missing values",
    "text": "1.2. Identify missing values\nMissing data may appear as blanks, ‚ÄúNA‚Äù, ‚Äú.‚Äù, or other placeholders. If not handled properly, this can cause errors or misinterpretation during analysis.\n\n\n# Check for missing values in each column\ncolSums(is.na(plant_data))\n\n# Visualise missing data pattern\nvisdat::vis_dat(plant_data)\n\nvis_dat() visualises the whole dataframe at once, and provides information about the class of the data input into R, as well as whether the data is missing or not.\nThe function vis_miss() provides a summary of whether the data is missing or not. It also provides the amount of missings in each columns.\n\n# Visualise missing data pattern\nvisdat::vis_miss(plant_data)\n\nOption: Removing columns with missing values\n\n# Removes all rows with NA in the dataset\nplant_data_clean &lt;- plant_data %&gt;% \n  drop_na()\n\n# not recommended if NA is scattered across columns (e.g. leaf1area) because some important variables might be dropped out.\n\n# Drop rows where NA is present in the elevation column only.\nplant_data_clean &lt;- plant_data %&gt;% \n  drop_na(elevation)\n\n# Run the vis_miss again on the clean data to check if the NA rows are removed. \nvisdat::vis_miss(plant_data_clean)\n\n\nExercise (5 min)\nüß™ Identify and handle missing values in the fake_data dataset\n\nWhich column contains missing variables?\nHow many missing values are there?\nRemove rows with missing values and create a new object called fake_data_clean.\nVisualise the new fake_data_clean with visdat::vis_dat(fake_data_clean).\n\n\n\nShow answer\n\n\n# Check for missing values in each column\ncolSums(is.na(fake_data)) # species_4, # 5 missing values\n\n# Visualise missing data pattern\nvisdat::vis_dat(fake_data) \n\n# Drop rows where NA is present in the elevation column only.\nfake_data_clean &lt;- fake_data %&gt;% \n  drop_na(species_4)\n\n# Run the vis_miss again on the clean data to check if the NA rows are removed. \nvisdat::vis_miss(fake_data_clean)",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week1_getting_started.html#check-for-duplicates",
    "href": "week1_getting_started.html#check-for-duplicates",
    "title": "1¬† Quality Check",
    "section": "1.3. Check for duplicates",
    "text": "1.3. Check for duplicates\n\nThere are two common duplicate types that can happen in your dataset.\n\nRow duplicates: where the values and names of two rows are identical 99% of the time, this is user error (e.g.¬†copy pasted). These must be identified and removed.\n\n\nsum(duplicated(plant_data))  # Returns the number of duplicate rows\n\n# View the duplicate rows themselves\nplant_data[duplicated(plant_data), ]\n\nIn the plant_data, there are no row duplicates.\n\nValue duplicates: 90% of value duplicates in a column might be biologically realistic responses and is likely due to rounding of values during recording (e.g.¬†values 2.5 and 2.5 might look duplicated due to user rounding. Actual values are 2.47 and 2.49). This is usually okay and can be kept in the dataset. User error occurs if there is a pattern in duplicates (e.g.¬†2,2,6,1,2,2,9,4,2,2,5,9). This can occur due to copy and pasting in the following row by accident.\n\nYou the researcher must decide whether these duplicate responses are real or due to user error.\n\nsum(duplicated(plant_data$leaf_dry_mass))  # Returns the number of duplicate rows\n\nplant_data[duplicated(plant_data$leaf_dry_mass) | duplicated(plant_data$leaf_dry_mass, fromLast = TRUE), ] # Returns all occurrences of duplicated numbers \n\nIn the leaf_dry_mass column, there are 51 value duplicates.\n\nExercise (3 min)\nüß™ Identify the duplicate row in the fake_data dataset\n\nWhere is the duplicate row?\nRemove the duplicate row. Either manually in Excel (easy), or an R function (challenge).\nAre there other duplicate values and do you know if they are ecologically relevant duplicates (similar response) or user error?\n\n\n\nShow answer\n\n\nsum(duplicated(fake_data)) # 1 duplicate found\n\n# View the duplicate rows themselves\nfake_data[duplicated(fake_data), ] #1 duplicate row in row 31\n\nsum(duplicated(fake_data$species_1))  # species_1 = 7\nsum(duplicated(fake_data$species_2))  # species_2 = 6\nsum(duplicated(fake_data$species_3))  # species_3 = 1\nsum(duplicated(fake_data$species_4))  # species_4 = 15",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week1_getting_started.html#check-for-outliers",
    "href": "week1_getting_started.html#check-for-outliers",
    "title": "1¬† Quality Check",
    "section": "2.1 Check for outliers",
    "text": "2.1 Check for outliers\nOutliers aren‚Äôt inherently ‚Äúbad,‚Äù but they can cause problems depending on the context and goals of your analysis. They can:\n\nSkew statistical results: A single extreme value can pull the mean far from the center, increase variability making data seem more spread than it really us, and can distrort the slope and intercept of linear models, leading to misleading predictions.\nCreate obscure patterns: Hide clusters or trends that would otherwise be visible.\nIndicate user error: Data entry mistakes (e.g., typing 1000 instead of 100), measurement errors (e.g., faulty sensors), incorrect data merging (e.g., mixing units like metres and feet).\n\nThere are different ways we can check for outliers. See a more comprehensive page for more options. Here, we will create two common plots to check for outliers, and run some simple methods for detecting and removing outliers.\n\nBoxplot\nWe can use the ggplot() function from the ggplot package to create a boxplot via geom_boxplot() showing the distribution of the lead2area data.\n\n# Boxplot of leaf2area to detect potential outliers\nggplot(plant_data, aes(y = leaf2area)) +\n  geom_boxplot(fill = \"lightgrey\") +\n  theme_bw()\n\nWarning: Removed 117 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\nHistogram\nAnother way we can visualise outliers is with histograms via geom_histogram() or density plots via geom_density()\n\n# Boxplot of height to detect potential outliers\nggplot(plant_data, aes(x = leaf2area)) +\n  geom_histogram() +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\nWarning: Removed 117 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nHere you can see one clear outlier with a value above 100. All other values are below 25. You can either manually remove the outlier on Excel, or with the following code below.\nOption: Remove outliers using the interquartile range (IQR) rule.\n\n# View potential outliers using IQR rule\nQ1 &lt;- quantile(plant_data$leaf2area, 0.25, na.rm = TRUE)\nQ3 &lt;- quantile(plant_data$leaf2area, 0.75, na.rm = TRUE)\nIQR &lt;- Q3 - Q1\n\n# Filter rows with height outside 1.5 * IQR range\noutliers &lt;- filter(plant, height &lt; (Q1 - 1.5 * IQR) | height &gt; (Q3 + 1.5 * IQR))\noutliers\n\nMake sure the numbers are biologically realistic based on intuition and comparing with the literature. If the values are unrealistic, it is a safe assumption to remove them.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week1_getting_started.html#is-the-data-normally-distributed",
    "href": "week1_getting_started.html#is-the-data-normally-distributed",
    "title": "1¬† Quality Check",
    "section": "2.2 Is the data normally distributed",
    "text": "2.2 Is the data normally distributed\nThis step is required to check if the data is suitable for certain types of analysis. Sometimes, transformation is required for certain data to meet the assumptions of certain statistical methods and improve the interpretability and performance of models. Many statistical techniques‚Äîlike linear regression, ANOVA, and t-tests‚Äîassume that the data is normally distributed, has constant variance, and is linearly related (from your MAS183 - Statistical Data Analysis and MAS224 - Biostatistical Methods units). If the data is skewed, has outliers, or shows non-constant variance (heteroscedasticity), these assumptions are violated, which can lead to biased estimates, incorrect conclusions, or poor model fit.\nBy applying transformations such as logarithmic, square root, or Box-Cox, we can:\n\nReduce skewness and make the distribution more symmetrical.\nStabilise variance across levels of an independent variable.\nImprove linearity between variables.\nMinimise the influence of outliers.\n\nLet‚Äôs check the distribution of leaf2area after removing that one outlier.\n\n# remove values above 100\nplant_data_clean &lt;- plant_data %&gt;%\n  filter(leaf2area &lt; 100)\n\nggplot(plant_data_clean, aes(x = leaf2area)) +\n  geom_histogram() +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\nLooks normally distributed to me! We will learn data transformation in next weeks workshop.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week1_getting_started.html#for-the-adventurous-folks-1",
    "href": "week1_getting_started.html#for-the-adventurous-folks-1",
    "title": "1¬† Quality Check",
    "section": "For the adventurous folks",
    "text": "For the adventurous folks\nHere we will start thinking about writing code efficiently. For example, you would have noticed by now that whatever raw data we load in R, any categorical columns are automatically listed as characters. So you can write a code that both loads the data and change the characters to factors in the same line of code (e.g.¬†using the dplyr::mutate() function). Load the plant_calcium_task.csv and change categorical variables from character and factor.\nRepeat the same assessment as above, but instead of correcting the errors by editing them on Excel, do all the corrections within the R environment. Visualise the clean version of the the data with a density plot but separate the density by the treatment groups (reference and W1 variables).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week1_getting_started.html#why-is-my-code-not-working",
    "href": "week1_getting_started.html#why-is-my-code-not-working",
    "title": "1¬† Quality Check",
    "section": "Why is my code not working!",
    "text": "Why is my code not working!\nComputers are only as smart as the humans that use them.\nIf your code is not working there is most likely a spelling mistake or a typographic error. These human errors are easy to miss but equally easy to fix!\nIf your code is not working take a moment to breathe. Then check for common, minor errors such as:\n\nSpelling mistakes\nWrong dataset name\nWrong variable (column) name\nMissing or wrong quotation mark\nMissing bracket\nInconsistent cases (e.g.¬†Uppercase)\nMissed a step\nInvalid syntax (e.g.¬†spaces)\nDuplicates of the same function with multiple errors ‚Äì keep your scripts tidy!\nThese reading/typing mistakes are the majority of encountered errors. They are not a big deal and are easily corrected.\n\nYou can and should easily fix the above mistakes yourself! We want you to know how to work problems out independently.\n\nExercise\nüß™ Why does this code not work?\n\nmy_variable &lt;- 10\nmy_varƒ±able\n#&gt; Error: object 'my_varƒ±able' not found\n\nLook carefully! (This may seem like an exercise in pointlessness, but training your brain to notice even the tiniest difference will pay off when programming.)",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week1_getting_started.html#additional-resource",
    "href": "week1_getting_started.html#additional-resource",
    "title": "1¬† Quality Check",
    "section": "Additional resource",
    "text": "Additional resource\n\nLoading other file types (if not .csv).\nHow to rename factor levels in R.\nCrashCourse Statistics video on Plots, Outliers, and Justin Timberlake, with examples of went to remove outliers.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week1_getting_started.html#footnotes",
    "href": "week1_getting_started.html#footnotes",
    "title": "1¬† Quality Check",
    "section": "",
    "text": "A vector is simply a list of items that are of the same type.‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Quality Check</span>"
    ]
  },
  {
    "objectID": "week2_tidy_data.html",
    "href": "week2_tidy_data.html",
    "title": "2¬† Tidy Data",
    "section": "",
    "text": "Background reading\nWeek 2 - Tidying data and clean code\nIn this workshop, you will learn how transform raw data to something usable for analysis, and get familiar with clean code.\nSometimes, it is rare that you get the data in exactly the right form you need from the raw data you import into R. Often you‚Äôll need to create some new variables or summaries, or maybe you just want to rename the variables or reorder the observations in order to make the data a little easier to work with. In this workshop you are going to learn the five key dplyr functions (part of tidyverse) that allow you to solve the vast majority of your data manipulation challenges:\nThese can all be used in conjunction with group_by() which changes the scope of each function from operating on the entire dataset to operating on it group-by-group. These six functions provide the verbs for a language of data manipulation.\nAll verbs work similarly:\nTogether these properties make it easy to chain together multiple simple steps to achieve a complex result. Let‚Äôs dive in and see how these verbs work.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Tidy Data</span>"
    ]
  },
  {
    "objectID": "week2_tidy_data.html#background-reading",
    "href": "week2_tidy_data.html#background-reading",
    "title": "2¬† Tidy Data",
    "section": "",
    "text": "Pick observations by their values (filter()). e.g.¬†keeping rows with values higher than 100.\nReorder the rows (arrange()). e.g.¬†rearrange a numeric column by the largest values.\nPick variables by their names (select()). e.g.¬†keeping selected columns only.\nCreate new variables with functions of existing variables (mutate()). e.g.¬†the sum of values from two numeric columns.\nCollapse many values down to a single summary (summarise()). e.g.¬†getting the overall mean of the dataset.\n\n\n\n\nThe first argument is a data frame.\nThe subsequent arguments describe what to do with the data frame, using the variable names (without quotes).\nThe result is a new data frame.\n\n\n\nStudy context\nIn order to know whether our imported data requires transformation before analysis, we need to know what we are analysing. Let‚Äôs stick with a familiar dataset, the plant_calcium.csv from this study.\nThe plant_calcium.csv dataset contains observations on sugar maple seedlings in untreated and calcium-treated watersheds at Hubbard Brook Experimental Forest in New Hampshire, USA.\nGrowth of sugar maples (Acer saccharum), known for their maple syrup and iconic leaf shape, can be stunted due to soil acidification from prolonged acid rain, which leaches calcium - a nutrient important for plant growth - from soils and stresses maple seedlings.\nTo investigate the impact of soil calcium supplementation on sugar maple seedling growth, researchers at the Hubbard Brook Long Term Ecological Research (LTER) site recorded ‚Äúgeneral sugar maple germinant health by height, leaf area, biomass, and chlorophyll content‚Äù (Juice et al., 2006) for seedlings in untreated and previously calcium-treated watersheds (Peters et al., 2004). By comparing seedling growth in calcium-treated (W1) versus untreated (Reference) watersheds, calcium impacts on sugar maple seedling growth can be explored.\n\n\n\nSugar maple seedling laboratory photos. Photo credit: Tom Siccama.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Tidy Data</span>"
    ]
  },
  {
    "objectID": "week2_tidy_data.html#exercise-15-min",
    "href": "week2_tidy_data.html#exercise-15-min",
    "title": "2¬† Tidy Data",
    "section": "Exercise (15 min)",
    "text": "Exercise (15 min)\nüß™ Use the previous functions to complete the following task for the fake_data below\n\nfake_data &lt;- data.frame(\n  site = c(\"A\", \"B\", \"C\", \"A\", \"B\", \"A\", \"B\", \"C\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"C\", \"C\", \"B\", \"A\", \"b\", \"C\", \"B\", \"C\", \"C\", \"A\", \"A\", \"A\", \"A\", \"B\", \"C\", \"C\", \"C\"),\n  species_1 = as.integer(c(7, 25, 30, 50, 38, 13, 5, 31, 34, 22, 41, 25, 22, 37, 39, 13, 45, 10, 40, 7, 28, 36, 19, 2, 12, 5, 16, 38, 27, 44, 44)),\n  species_2 = as.integer(c(9, 8, 1 , 7, 9 , 9, 4, 8, 1, 7, 1, 6, 4, 4, 7, 2, 8, 7, 2, 9, 9, 2, 6, 8, 6, 6, 17, 1, 8, 4, 4)),\n  species_3 = as.integer(c(190, 160, 70, 430, 310, 99, 530, 420, 371, 357, 198, 171, 463, 124, 254, 484, 435, 409, 122, 305, 410, 162, 473, 200, 401, 273, 421, 419, 293, 487, 487)),\n  species_4 = as.integer(c(2, 0, 4, 8, 6, 3, 7, 4, 2, NA, 35, 10, 6, 4, 8, 1, 1, 0, NA, 4, 6, 8, 10, 6, 2, 5, 10, 7, NA, NA, NA))\n  )\n\n\nConduct the usual quality check on this dataset (slightly different mistakes).\nCreate a new variable column called total_sp that combines all the species.\nSelect only the site and total_sp variable into a new dataframe.\nCalculate the mean, minimum, maximum, and count of total_sp by site.\n\nQuestion:\n\nWhat is the mean total abundance in site B?\nWhat is the problem with using mean here? Is there a better way to calculate central tendancy for dount data? (hint: think of decimals in this context).\nWhich site has the highest average species abundance?\nWhich site has the most replicate samples?\n\n\n\nShow answer\n\n\nstr(fake_data)\n\n# there is an inconsistent coding in one of the categorical variables, and an extreme value in one of the numeric variables to remove.\n\nfake_data_clean &lt;- fake_data %&gt;%\n  dplyr::mutate(site = recode(site, \"b\" = \"B\"),\n                site = as.factor(site)) %&gt;%\n  dplyr::filter(species_4 &lt; 30) %&gt;%\n  dplyr::mutate(total_sp = species_1 + species_2 + species_3 + species_4) %&gt;%\n  dplyr::select(site, total_sp)\n\nfake_data_clean %&gt;%\n  dplyr::group_by(site) %&gt;%\n  dplyr::summarise(mean = mean(total_sp),\n                   min  = min(total_sp),\n                   max  = max(total_sp),\n                   n = n())\n\n# 1. 361.25 \n# 2. Mode more suitable for integers\n# 3. Site B\n# 4. site A",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Tidy Data</span>"
    ]
  },
  {
    "objectID": "week2_tidy_data.html#exercise-15-min-1",
    "href": "week2_tidy_data.html#exercise-15-min-1",
    "title": "2¬† Tidy Data",
    "section": "Exercise (15 min)",
    "text": "Exercise (15 min)\nüß™ Clean the code below\nYour colleague got a new job and you have been promoted to his position where you are taking over his unfinished projects. The ecological data has been collected and some quick analysis was performed. But, you noticed that he didnt perform a quality check on the raw data and the # explanations are not clear. The current state is not suitable for the client so you are assigned to clean.\nClean the code where relevent, and check if all the code is working on your end.\nNote: change the working directory to your folder and load the plant_calcium.csv to work on. Note 2: The same errors to fix are from the week 2 - data quality workshop.\n\n# Exercise 2\n# Cleaning code and tidying dataset\n# John Smith, 25-03/2025\n\n## Set up ## ----------------------------------------------------------------\nlibrary(tiderVerse)\n\n# Set my directory\nsetwd(\"your working directory\")\n\n## Loading and cleaning data ## ---------------------------------------------\n\n# Load raw data\nplant data &lt;- read_csv(\"data/plant_calcium.csv\")\nstr(plant data)\n\n## Analysis ## -------------------------------------------------------------\n\n# Fit model: height explained by elevation\nmodel &lt;- lm(stem_dry_mass ~ stem_length, data = plant_data)\n\n# Check model summary\nsummary(model)\n\n## Visualisation ## --------------------------------------------------------\n\n# Creating scatterplot figure\nplant_data %&gt;%\n  ggplot() +\n  geom_point(aes(x = stem_length, y = Stem_dry_mass)) +\n  labs(\n    x = \"Stem Length (mm)\",\n    y = \"Stem Dry Mass (g)\",\n    title = \"Stem Dry Mass vs. Stem Length in Sugar Maple Seedlings\",\n    subtitle = \"Hubbard Brook LTER\"\n  ) +\n  theme_minimal()\n\n\n\nShow answer\n\n\n# Exercise 2\n# Cleaning code and tidying dataset\n# John Smith, 25-03-2025\n\n## Set up ## ----------------------------------------------------------------\nlibrary(tidyverse)\n\n# Set my directory\nsetwd(\"C:/Users/75002992/OneDrive - Murdoch University/Teaching/ECS200 - Research Methods in Ecology/ECS200 - Workshop/\")\n\n## Loading and cleaning data ## ---------------------------------------------\n\n# Load raw data\nplant_data &lt;- read_csv(\"data/plant_calcium.csv\")\nstr(plant_data)\n\n\n# Correct class type\nplant_data &lt;- plant_data %&gt;%\n  mutate(watershed = as.factor(watershed),\n         elevation = as.factor(elevation))\n\n# Check for missing values in each column\ncolSums(is.na(plant_data))\n\n# Visualise missing data pattern\nvisdat::vis_dat(plant_data_clean)\n\n# Remove NA rows based on missing elevation data\nplant_data &lt;- plant_data %&gt;% \n  drop_na(elevation)\n\n# Check for duplicate rows\nsum(duplicated(plant_data))  # None\n\n# Check for outliers\n\nggplot(plant_data, aes(x = leaf2area)) +\n  geom_histogram() +\n  theme_bw()\n\n# create a clean dataset after filtering the outlier\nplant_data_clean &lt;- plant_data %&gt;%\n  dplyr::filter(leaf2area &lt; 90)\n\n## Analysis ## -------------------------------------------------------------\n\n# Fit model: height explained by elevation\ndry_length_mod &lt;- lm(stem_dry_mass ~ stem_length, data = plant_data_clean)\n\n# Check model summary\nsummary(dry_length_mod)\n\n## Visualisation ## --------------------------------------------------------\n\n# Creating scatterplot figure\nplant_data_clean %&gt;%\n  ggplot() +\n  geom_point(aes(x = stem_length, y = stem_dry_mass)) +\n  labs(\n    x = \"Stem Length (mm)\",\n    y = \"Stem Dry Mass (g)\",\n    title = \"Stem Dry Mass vs. Stem Length in Sugar Maple Seedlings\",\n    subtitle = \"Hubbard Brook LTER\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Tidy Data</span>"
    ]
  },
  {
    "objectID": "week2_tidy_data.html#for-the-adventurous-folks",
    "href": "week2_tidy_data.html#for-the-adventurous-folks",
    "title": "2¬† Tidy Data",
    "section": "For the adventurous folks",
    "text": "For the adventurous folks\nYou‚Äôve learned how to use the core dplyr verbs ‚Äî now let‚Äôs practice building more powerful and efficient workflows by combining multiple functions in clean, compact code.\n1. Take your cleaned dataset plant_task_data_clean and write one pipeline that:\n\nFilters only W1 watershed and year 2004.\nCreates a new variable total_mass_g from stem_dry_mass + leaf_dry_mass, multiplied by 1000\nSelects only the new variable and stem_length\nFilters any rows with stem_length greater than 200 mm.\nArranges the result by total_mass_g in descending order.\n\nUse %&gt;% or |&gt; and avoid creating intermediate objects.\n2. Using group_by() and summarise() in a single chain:\n\nGroup the data by watershed and year.\nCalculate the mean, coefficient of variation, and count of total_mass_g.\nArrange by year in ascending order.\n\n3. Write a function that:\n\nTakes a numeric column as input.\nFilters out outliers using the 1.5 √ó IQR rule.\nReturns the filtered data.\n\nTry applying it to leaf_dry_mass and stem_length.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Tidy Data</span>"
    ]
  },
  {
    "objectID": "week3_diversity_index.html",
    "href": "week3_diversity_index.html",
    "title": "3¬† Diversity Indices",
    "section": "",
    "text": "Background reading\nWeek 3 - Measurements of biodiversity\nIn this workshop, you will learn different types of ways to quantify diversity and abundance in your dataset. This section is particularly important for groups who are doing field studies, but this quantitative skill is also useful if you have a job in field ecology.\nBiodiversity can be measured using different scales and metrics, most commonly by looking at species richness (the number of different species) and species evenness (the relative proportion of individuals in each species). Other measurements include alpha, beta, and gamma diversity, which describe diversity within a single site, between sites, and across a larger region, respectively. Here, we will focus on the most common ways of quantifying diversity and abundance.\nAbundance metrics\nSpecies richness metrics\nDiversity indices\nOther types of diversity metrics such as R√©nyi and Tsallis diversities, taxonomic diversity and taxonomic distinctness, alpha and beta diveristy can also be done with the vegan R package.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Diversity Indices</span>"
    ]
  },
  {
    "objectID": "week3_diversity_index.html#background-reading",
    "href": "week3_diversity_index.html#background-reading",
    "title": "3¬† Diversity Indices",
    "section": "",
    "text": "Absolute abundance (\\(N_i\\)): The total number of individuals of a species recorded. A simple and intuitive calculation, but sensitive to sampling effort, i.e, cannot compare across surveys without standardisation. Only use when sampling effort is standardised (e.g., same transect length, trap nights).\nRelative abundance (\\(p_i\\)): Comparable across communities and is foundational for many diversity indices. Only use when communities have differing total abundance, or you need proportional representation, or over time.\nDensity (\\(d_i\\); individuals per area or effort): Allows spatial comparison, but requires accurate area/effort estimates. Appropriate for quadrat/plot/transect sampling.\n\n\n\nSpecies richness (\\(S\\)): The total number of unique species. A sample and intuitive calculation, but highly sensitive to sample size and rare species. Only use when comparing equally-sampled plots or as a component in more complex metrics.\nRarefied richness: Standardised species richness for a fixed number of individuals or samples. Allows fair comparison across unequal sampling effort, but assumes random sampling, i.e low resolution when sample sizes differ greatly. Only use in surveys with unequal effort.\n\n\n\nShannon diversity index (\\(H'\\)): Incorporates both species richness and evenness (the relative abundance of each species). Widely used, but difficult to interpret ecologically. Moderately sensitive to rare species, but good for comparing diversity across sites or time when both abundance and richness matter.\nSimpson‚Äôs diversity index (\\(D\\)): Emphasises the dominance of species and is less sensitive to rare species. However, underweights rare species and may mask losses in low-abundance taxa. Use in management-focused studies (dominance effects), and stable community comparisons.\n\n\n\nNew functions\nHere are some new functions from the tidyverse you will be using in this workshop.\n\npivot_longer() converts data from wide format to long format.\nstarts_with()*used inside select() to choose columns whose names begin with a specific string.\nacross()* applies a function to multiple columns in a summarise() or mutate() call. e.g.¬†everything() = select all columns and sum = function to apply.\n.x* is a pronoun used inside anonymous functions in tidyverse pipelines‚Äîespecially in across() and map(). It represents the current column being processed.\n\n‚Äô*‚Äô See ‚ÄòRelative abundance‚Äô section for example use.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Diversity Indices</span>"
    ]
  },
  {
    "objectID": "week3_diversity_index.html#calculations-of-abundance",
    "href": "week3_diversity_index.html#calculations-of-abundance",
    "title": "3¬† Diversity Indices",
    "section": "Calculations of abundance",
    "text": "Calculations of abundance\nWe will start with this fake ecological survey data. Also, to calculate Shannon and Simpson‚Äôs diversity, we will need the the vegan package.\n\n#install.packages('vegan')\n\n# Load library\nlibrary(tidyverse)\nlibrary(vegan)\n\n# Create fake survey data\nfake_data &lt;- data.frame(\n  site = c(\"A\",\"A\",\"A\",\"A\",\"A\",\n           \"B\",\"B\",\"B\",\"b\",\"B\",\n           \"C\",\"C\",\"C\",\"C\",\"C\"),\n  species_1 = c(57,73,20,75,83,\n                41,6,61,45,2,\n                0,93,0,0,86),\n  species_2 = c(31,12,4,41,4,\n                49,2,7,7,9,\n                54,64,35,38,53),\n  species_3 = c(0,38,3,0,39,\n                0,29,24,15,23,\n                10,0,1,5,2),\n  species_4 = c(11,28,19,0,1,\n                34,7,0,1,0,\n                1,0,12,45,5),\n  species_5 = c(0,0,0,0,0,\n                4,5,0,0,0,\n                3,1,0,1,2)\n)\n\n# Clean data identified with incosistencies in format\nfake_data_clean &lt;- fake_data %&gt;%\n  dplyr::mutate(site = recode(site, \"b\" = \"B\"),\n                site = as.factor(site))\n\n\nAbsolute abundanceRelative abundanceDensity\n\n\nEquation:\n\\[\nN_i = \\sum_{j=1}^{k} n_{ij}\n\\] where \\(n_{ij}\\) - individuals of species \\(i\\) in sample \\(j\\). Essentially its just the number of individuals of that species counted.\nTo calculate absolute abundance of one species in R, here is the following code.\n\n# for one species\nsum(fake_data_clean$species_1) # Total abundance for all or individual species across all sites\n\nYou can see that the total number of species_1 in the survey is 642.\nYou may want to calculate abundance for each species, by site.\n\nfake_data_long &lt;- fake_data_clean %&gt;% \n  tidyr::pivot_longer(!site, names_to = \"species\", values_to = \"abundance\") # convert wide format to long format (easier to summaries groups)\n\nabundance_sum &lt;- fake_data_long %&gt;%\n  group_by(site, species) %&gt;%\n  summarise(total = sum(abundance))\n\n# Visulise abundance\nabundance_sum %&gt;%\n  ggplot() +\n  geom_bar(aes(x = species, y = total), stat = \"identity\") +\n  labs(x = \"Species\", y = \"Total abundance\") +\n  theme_bw() +\n  coord_flip()\n\n\n\n\n\n\n\n\nYou can see that the total number of species_1 is 308 in site A, 155 in site B, and 179 in site C.\n\n\nEquation:\n\\[\np_i = \\frac{N_i}{\\sum_{i=1}^{S} N_i} = \\frac{N_i}{N}\n\\]\nwhere \\(p_i\\) is the relative abundance of species \\(i\\), \\(N_i\\) is the abundance of species \\(i\\), \\(\\sum_{i=1}^{S} N_i = N\\) is the total abundance across all species in the community, \\(S\\) is the total number of species.\nFor example, if 10 of the 50 individuals in a quadrat are species A: \\(p_i\\) = 10/50 = 0.20, meaning species A makes up 20% of the community.\nTo calculate relative abundance of each species in R, here is the following code.\n\n# Option 1 - using wide format data\nfake_data_clean %&gt;%\n  select(starts_with(\"species_\")) %&gt;% # select all columns with \"species_\"\n  summarise(across(everything(), sum)) %&gt;%      # For each column (using across), calculate the sum of all values (everything). i.e total abundance per species\n  mutate(total = sum(across(everything()))) %&gt;% # total abundance of all species\n  mutate(across(starts_with(\"species_\"), ~ .x / total)) # For each species column, take its values (.x) and divide by total.\n\n  species_1 species_2 species_3 species_4  species_5 total\n1 0.4517945 0.2885292 0.1330049 0.1154117 0.01125968  1421\n\n# Option 2 - using long format data\nrelative_sum &lt;- fake_data_long %&gt;%\n  group_by(species) %&gt;%\n  summarise(species_sum = sum(abundance),\n         relative_abundance = species_sum / sum(fake_data_long$abundance))\n\n# Visualise relative abundance by species\nrelative_sum %&gt;%\n  ggplot() +\n  geom_bar(aes(x = species, y = relative_abundance), stat = \"identity\") +\n  labs(x = \"Species\", y = \"Relative abundance\") +\n  theme_bw() +\n  coord_flip()\n\n\n\n\n\n\n\n\nTo calculate relative abundance of each species within each site.\n\n# Option 1 - using wide format data\nfake_data_clean %&gt;%\n  group_by(site) %&gt;%\n  summarise(across(starts_with(\"species_\"), sum)) %&gt;%   # total abundance per species per site\n  mutate(total = rowSums(across(starts_with(\"species_\")))) %&gt;%  # site-level total abundance\n  mutate(across(starts_with(\"species_\"), ~ .x / total)) # divide species abundance by site total\n\n# A tibble: 3 √ó 7\n  site  species_1 species_2 species_3 species_4 species_5 total\n  &lt;fct&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 A         0.571     0.171    0.148      0.109    0        539\n2 B         0.418     0.199    0.245      0.113    0.0243   371\n3 C         0.350     0.477    0.0352     0.123    0.0137   511\n\n# Option 2 - using long format data\nrelative_site_sum &lt;- fake_data_long %&gt;%\n  group_by(site, species) %&gt;%\n  summarise(total_abundance = sum(abundance)) %&gt;%\n  mutate(site_total = sum(total_abundance),\n         rel_abundance = total_abundance / site_total)\n\n# Visualise results\nrelative_site_sum %&gt;%\n  ggplot() +\n  geom_bar(aes(x = site, y = rel_abundance, fill = species), stat = \"identity\", position = position_dodge()) +\n  labs(x = \"Sites\", y = \"Relative abundance\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nWe see that species_1 makes up about 57% of the sample for Site A, and species_4 makes up about 11% of the sample. Once we calculate relative densities for each species at each site, this eliminates differences in total density at each site because all sites then total to 1.\n\n\nEquation:\n\\[\nd_i = \\frac{N_i}{A}\n\\]\nwhere \\(d_i\\) is the density of species \\(i\\) (e.g, individuals/ha), \\(N_i\\) absolute abundance of species \\(i\\), \\(A\\) is the area sampled (e.g.¬†m2, ha, km2).\nFor example, if you counted 42 lizards in a 0.5 ha plot: \\(d_i\\) = 42/0.5 = 84 individuals/ha.\nTo calculate density for each site per sampling event (individuals/site/sampling event) in R, here is the following code.\n\n# Option 1 - wide format\nfake_data_clean %&gt;%\n  group_by(site) %&gt;%\n  summarise(round(across(starts_with(\"species\"), mean, na.rm = TRUE))) # calculates the mean count per site across the sampling period.\n\n# A tibble: 3 √ó 6\n  site  species_1 species_2 species_3 species_4 species_5\n  &lt;fct&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 A            62        18        16        12         0\n2 B            31        15        18         8         2\n3 C            36        49         4        13         1\n\n# Option 2 - long format\ndensity_sum &lt;- fake_data_long %&gt;%\n  group_by(site, species) %&gt;%\n  summarise(density = round(mean(abundance))) # calculates the mean count per site across the sampling period.\n\n# Visualise results\ndensity_sum %&gt;%\n  ggplot() +\n  geom_bar(aes(x = site, y = density, fill = species), stat = \"identity\", position = position_dodge()) +\n  labs(x = \"Sites\", y = \"Density (n/sample effort)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nWe can see here that site A has 62 individuals per sampling effort for species_1, while site B has 31 indidvuals per sampling effort for species_1.\nIf you want density of all individuals by site, then use the following code.\n\nfake_data_long %&gt;%\n  group_by(site) %&gt;%\n  summarise(density = round(mean(abundance))) # calculates the mean count per site across the sampling period.\n\nSite A has an average of 22 individuals per sampling effort, while site B has an average of 20 individuals per sampling effort.\n\n\n\n\nExercise 1 (10 min)\nüß™ Complete the following task for the excerise_survey_data below\n\nCalculate the absolute abundance, relative abundance, and density of all species by sites\nWhat is the absolute density of species_1?\nWhat is the relative abundance of species_2 in site B?\nWhat is the mean density of species_3?\n\n\nexcerise_survey_data &lt;- data.frame(\n  site = c(\"A\",\"A\",\"A\",\"B\",\"B\",\"B\",\"C\",\"C\",\"C\"),\n  plot = c(1,2,3,1,2,3,1,2,3),\n  species_1 = c(12, 7, 15, 4, 9, 6, 20, 18, 25),\n  species_2 = c(5, 2, 1, 10, 7, 4, 3, 1, 0),\n  species_3 = c(0, 3, 2, 6, 4, 5, 0, 1, 2),\n  species_4 = c(8, 6, 3, 1, 4, 2, 10, 7, 5)\n)\n\n\n\nShow answer\n\n\nexcerise_survey_long &lt;- excerise_survey_data %&gt;%\n  tidyr::pivot_longer(!c(site, plot), names_to = \"species\", values_to = \"abundance\")# convert wide format to long format (easier to summaries groups)\n  \nexcerise_survey_sum &lt;- excerise_survey_long %&gt;%\n  group_by(site, species) %&gt;%\n  summarise(species_sum = sum(abundance), # calculates abundance\n            relative = (species_sum / sum(excerise_survey_long$abundance) * 100), # calculates relative abundance\n            density = round(mean(abundance)) # calculates density (individuals/plot)\n            ) \n\n# answer 1 \nexcerise_survey_sum %&gt;%\n  filter(species == \"species_1\") %&gt;%\n  pull(species_sum) %&gt;%\n  sum()\n\n# answer 2\nexcerise_survey_sum %&gt;%\n  filter(species == \"species_2\", site == \"B\") %&gt;%\n  select(relative) \n\n# answer 3\nexcerise_survey_sum %&gt;%\n  filter(species == \"species_3\") %&gt;%\n  pull(density) %&gt;%\n  mean()\n\n\n# 1. 116\n# 2. 9%\n# 3. 2.6",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Diversity Indices</span>"
    ]
  },
  {
    "objectID": "week3_diversity_index.html#calculations-of-species-richness",
    "href": "week3_diversity_index.html#calculations-of-species-richness",
    "title": "3¬† Diversity Indices",
    "section": "Calculations of species richness",
    "text": "Calculations of species richness\n\nSpecies richnessRarefied richness\n\n\nEquation:\n\\[\nS = number \\, of \\, species \\, observed\n\\]\nTo calculate species richness in R, here is the following code. Note, you will need to remove zeros when using length() to count number of species because length will include zero.\n\n# Option 1 - using tidyverse\nfake_data_long %&gt;%\n  filter(abundance != 0) %&gt;% # remove rows with zeros (e.g. no species 5 in site A)\n  group_by(site) %&gt;%\n  summarise(total = length(unique(species))) \n\nIn our fake dataset, we have four species in site A, and all five species in site B and C. Note, if we includes zeros in this calculation, we would get species_5 in the count which means all sites would have five species, which is incorrect.\n\n\nSpecies richness increases with sample size, and differences in richness actually may be caused by differences in sample size. To solve this problem, we may try to rarefy species richness to the same number of individuals.\nTo calculate absolute abundance of one species in R, here is the following code.\n\n# sum species counts per site\nsite_counts &lt;- fake_data_clean %&gt;%\n  group_by(site) %&gt;%\n  summarise(across(where(is.numeric), sum))\n\n\n# Rarefied richness needs a ‚Äúsample size‚Äù = smallest total abundance across sites.\nnmin &lt;- rowSums(site_counts[ , -1]) %&gt;% min()\n\nrarefied_richness_output &lt;- vegan::rarefy(site_counts[ , -1], sample = nmin)\n\n# add rarefied results to sites\nrarefied_richness &lt;- bind_cols(site = site_counts$site,\n                               rarefied_richness = rarefied_richness_output)\n\nIn this fake dataset, the results are the same as your standard species richness count. When you have more complicated and more variable datasets with lots of rare species, this calculation might be useful. Always justify which metric you plan to use in your report.\n\n\n\n\nExercise 2 (10 min)\nüß™ Complete the following task for the excerise_survey_data below\n\nCalculate the species richness by sites.\nWhat is the richness of site C?\n\n\n\nShow answer\n\n\n# Species richness\nexcerise_survey_long %&gt;%\n  filter(abundance != 0) %&gt;% # remove rows with zeros (e.g. no species 5 in site A)\n  group_by(site) %&gt;%\n  summarise(total = length(unique(species))) \n\n# 1. 4",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Diversity Indices</span>"
    ]
  },
  {
    "objectID": "week3_diversity_index.html#calculations-of-diversity",
    "href": "week3_diversity_index.html#calculations-of-diversity",
    "title": "3¬† Diversity Indices",
    "section": "Calculations of diversity",
    "text": "Calculations of diversity\n\nShannon diversity indexSimpson‚Äôs diversity index\n\n\nEquation:\n\\[\nH' = - \\sum_{i=1}^{S} p_i \\,\\ln(p_i)\n\\] where \\(H'\\) is Shannon diversity index, \\(S\\) is the total number of species in the community (species richness), \\(p_i\\) is the relative abundance of species \\(i\\) (see relative abundance). High \\(H'\\) = many species, relatively even abundances, while low \\(H'\\) = few species or dominance by one/few species.\nTo calculate \\(H'\\) in R, here is the following code. Note, y\n\nshannon_output &lt;- vegan::diversity(site_counts[, -1], index = \"shannon\") # remove site column [,-1] for the diversity function to work\n\n# add H results to sites\nshannon_sum &lt;- bind_cols(site = site_counts$site,\n                               shannon = shannon_output)\n\n# Visualise results\nshannon_sum %&gt;%\n  ggplot() +\n  geom_bar(aes(x = site, y = shannon), stat = \"identity\") +\n  labs(x = \"Sites\", y = \"Shannon diveristy index (H')\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nIf \\(H'\\) = 0, only one species is present (no diversity). A value of 1.36 in site B means site B has slighty higher diversity than site A and site C. i.e.¬†more species and/or a more even distribution of individuals among species.\n\n\nEquation:\n\\[\nD_1 = 1 - \\sum_{i=1}^{S} p_i^2\n\\]\nwhere \\(D_1'\\) is Simpson‚Äôs diversity index, \\(S\\) is the total number of species in the community (species richness), \\(p_i\\) is the relative abundance of species \\(i\\) (see relative abundance). High \\(D_1\\) = high diversity, while low \\(D_1\\) = low diversity.\nFor inverse Simpson‚Äôs diversity index, the equation is:\n\\[\nD_2 = \\frac{1}{\\sum_{i=1}^{S} p_i^2}\n\\] where \\(D_2\\) is the inverse of Simpson‚Äôs diversity index. if \\(D_2\\) = 1, only one species is present, and if \\(D_2\\) is higher then more species are present/or more even distribution.\nTo calculate \\(D_1\\) in R, here is the following code.\n\nsimpson_output &lt;- vegan::diversity(site_counts[ , -1], index = \"simpson\") # remove site column [,-1] for the diversity function to work\n\n# add D1 results to sites\nsimpson_sum &lt;- bind_cols(site = site_counts$site,\n                               simpson = simpson_output)\n\n# Visualise results\nsimpson_sum %&gt;%\n  ggplot() +\n  geom_bar(aes(x = site, y = simpson), stat = \"identity\") +\n  labs(x = \"Sites\", y = \"Simpson's diveristy index (D1)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nSimilar to Shannon diversity index, site B has higher \\(D_1\\) of 0.71 compared to the other two sites.\n\n\n\n\nExercise 3 (10 min)\nüß™ Complete the following task for the fake_data_clean below\n\nCalculate the Shannon diversity index, and Simpson‚Äôs diversity index by sites\nWhat is the diversity of site A using the Shannon diversity index (\\(H'\\)) method?\nWhat is the diversity of site B using the inverse Simpson‚Äôs diversity index (\\(D_2\\)) method?\n\n\n\nShow answer\n\n\n# sum species counts per site\nexcerise_survey_sum &lt;- excerise_survey_data %&gt;%\n  group_by(site) %&gt;%\n  summarise(across(where(is.numeric), sum))\n\n# Shannon diversity\nbind_cols(site = excerise_survey_sum$site, \n          shannon = vegan::diversity(excerise_survey_sum[, -c(1, 2)], index = \"shannon\"),\n          simpson = vegan::diversity(excerise_survey_sum[, -c(1, 2)], index = \"invsimpson\"))\n\n# 1. 1.14\n# 2. 3.5",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Diversity Indices</span>"
    ]
  },
  {
    "objectID": "week3_diversity_index.html#for-the-adventurous-folks",
    "href": "week3_diversity_index.html#for-the-adventurous-folks",
    "title": "3¬† Diversity Indices",
    "section": "For the adventurous folks",
    "text": "For the adventurous folks\nTry to get Shannon diversity index by treatment and block. Convert wide data to sums per treatment x block.\nSee if you can replicate this figure.\n\nshannon_inv %&gt;%\n  ggplot() +\n  geom_point(aes(x = treatment, y = shannon), size = 2) +\n  labs(x = \"Treatment\", y = \"Shannon diveristy index (H')\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nThis is more reflective of the normal variation across experimental blocks and where your report should be going towards instead ot the mean only.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Diversity Indices</span>"
    ]
  },
  {
    "objectID": "week4_descriptive_stats.html",
    "href": "week4_descriptive_stats.html",
    "title": "4¬† Descriptive Stats",
    "section": "",
    "text": "Background reading\nWeek 4 - Descriptive stats and plotting data\nIn this workshop, you will learn how to summarise different types of ecological data using appropriate statistical measures and visualisations. Understanding the right measures of central tendency and spread is critical before conducting any formal hypothesis testing.\nBefore we can decide on the appropriate descriptive stats it helps to understand the scale of your variable. The table below outlines appropriate measures for both qualitative and quantitative variables:\nWhen laying out your datasheet for your study, it is important to know what data types each column will be when imported into R. Here is an example data sheet that is color-coded according to the type of variable: nominal, continuous, ordinal, and binary.\nKey Terms used in this workshop:\nIf you are still confused by the terminologies, the CrashCourse Statistics videos on the Mean, Median, and Mode: Measures of Central Tendency (11:22 min long), and the Measures of Spread (11:46 min long) better explains the terms visually.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Descriptive Stats</span>"
    ]
  },
  {
    "objectID": "week4_descriptive_stats.html#background-reading",
    "href": "week4_descriptive_stats.html#background-reading",
    "title": "4¬† Descriptive Stats",
    "section": "",
    "text": "Data Scale\nType\nDefinition\nExamples\nCentral Tendency\nSpread/Variation\n\n\n\n\nNominal\nQualitative\nNamed categories with no intrinsic order\nsex (male/female), species name\nMode\nCount, Proportion\n\n\nOrdinal\nQualitative\nNamed categories data with a natural order\nlife stage (egg, juvenile, adult)\nMedian, Mode\nRange, IQR\n\n\nInterval\nQuantitative\nEqual intervals between values but no true zero\ntemperature, pH, dates\nMean, Median\nSD, SE, CI\n\n\nRatio\nQuantitative\nEqual intervals and a true zero\nlength, age, body mass\nMean, Median\nSD, SE, CV, IQR, CI, variance\n\n\n\n\n\n\n\nMean: Average value. Use with symmetric, normally distributed data.\nMedian: Middle value. More robust to outliers and skewed data.\nMode: Most frequent value (useful for categories).\nStandard Deviation (SD): How spread out the data is.\nStandard Error (SE): SD divided by the square root of n (how precise the mean is).\nCoefficient of Variation (CV): SD / Mean. Compares spread across variables.\nInterquartile Range (IQR): Range between 25th and 75th percentiles.\nConfidence Interval (CI): A range that likely contains the true mean.\nVariance: How much values differ from the average value.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Descriptive Stats</span>"
    ]
  },
  {
    "objectID": "week4_descriptive_stats.html#plot-types",
    "href": "week4_descriptive_stats.html#plot-types",
    "title": "4¬† Descriptive Stats",
    "section": "Plot Types",
    "text": "Plot Types\nThere are so many ways to visualise your data beyond this workshop, so we will only focus a few common ones you will likely use in your report.\n\nLet‚Äôs say we are interested in visualising at differences in stem length in calcium-treated (W1) versus untreated (Reference) watersheds, there are a couple of ways we can visualise this.\n\n# Load a CSV file\nplant_task_clean_data &lt;- read_csv(\"https://raw.githubusercontent.com/nicholaswunz/ECS200-Workshop/refs/heads/main/data/plant_calcium_task.csv\") %&gt;%\n  dplyr::mutate(watershed = recode(watershed, \"W2\" = \"W1\"),\n                watershed = as.factor(watershed),\n                transect  = as.factor(transect)) %&gt;%\n  dplyr::filter(stem_dry_mass &lt; 1)\n\n\nHistogram or densityBoxplotBar plot or dot plotScatter plot\n\n\nA histogram and density plot takes as input a numeric variable only. The variable is cut into several bins, and the number of observation per bin is represented by the height of the bar. It is possible to represent the distribution of several variable on the same axis using this technique.\nTo create a histogram by group, use the geom_histogram() function within ggplot.\n\nplant_task_clean_data %&gt;%\n  ggplot(aes(x = stem_length, fill = watershed)) +\n  geom_histogram(alpha = 0.4, position = \"identity\") # changed transparency due to overlap in watershed groups\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\nTo create a density plot by group, use the geom_density() function within ggplot.\n\nplant_task_clean_data %&gt;%\n  ggplot(aes(x = stem_length, fill = watershed)) +\n  geom_density(alpha = 0.4, position = \"identity\") # changed transparency due to overlap in watershed groups\n\n\n\n\n\n\n\n\n\n\nA boxplot provides an effective summary of one or more numeric variables, showcasing key statistical features through its distinct elements:\n\nMedian Line: The line that divides the box represents the median of the data. For example, if the median is 10, this indicates that half of the data points lie below 10 and half above.\nQuartiles: The ends of the box indicate the upper (Q3) and lower (Q1) quartiles. If Q3 is 15, this means that 75% of the observations fall below this value.\nInterquartile Range (IQR): The difference between Quartiles 1 and 3 is known as the interquartile range (IQR), which measures the spread of the middle 50% of the data.\nWhiskers: The lines extending from the box show the range of values within Q3 + 1.5 √ó IQR to Q1 - 1.5 √ó IQR, representing the highest and lowest values, excluding outliers.\nOutliers: Dots (or other markers) beyond the whiskers indicate potential outliers in the dataset.\n\n\nTo create a boxplot by group, use the geom_boxplot() function within ggplot.\n\nplant_task_clean_data %&gt;%\n  ggplot(aes(x = watershed, y = stem_length)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nTo plot the mean and standard deviation as a bar plot, use the geom_bar() function with geom_errorbar().\n\nplant_sum &lt;- plant_task_clean_data %&gt;%\n  group_by(watershed) %&gt;%\n  summarise(mean = mean(stem_length),\n            sd = sd(stem_length))\n\n\nplant_sum %&gt;%\n  ggplot(aes(x = watershed)) +\n  geom_bar(aes(y = mean), stat = \"identity\") +\n  geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd), width = .02)\n\n\n\n\n\n\n\n\nTo plot the mean and standard deviation as a dot plot, use the geom_pointrange(). It is also useful to include the raw data in this case, which you will need to call in the plant_task_clean_data and plant_sum separately and plot the raw data with the geom_jitter() function.\n\n# mean +/- sd only.\nmean_plot &lt;- plant_sum %&gt;%\n  ggplot() + \n  geom_pointrange(aes(x = watershed, y = mean, ymin = mean-sd, ymax = mean+sd))\n\n# including raw data\nraw_plot &lt;- ggplot() + \n  geom_jitter(data = plant_task_clean_data, aes(x = watershed, y = stem_length), \n              alpha = 0.1, position = position_jitter(0.2)) + #raw data\n  geom_pointrange(data = plant_sum, aes(x = watershed, y = mean, \n                                      ymin = mean-sd, ymax = mean+sd))\n\ncowplot::plot_grid(mean_plot, raw_plot, ncol = 2, align = \"v\")\n\n\n\n\n\n\n\n\n\n\nA scatterplot displays the relationship between 2 numeric variables. For each data point, the value of its first variable is represented on the X axis, the second on the Y axis\nTo create a scatterplot, use the geom_point() function within ggplot.\n\nplant_task_clean_data %&gt;%\n  ggplot(aes(x = stem_length, y = stem_dry_mass)) +\n  geom_point()\n\n\n\n\n\n\n\n\nTo create a scatterplot by group, include a colour or shape level within ggplot.\n\ncolor_plot &lt;- plant_task_clean_data %&gt;%\n  ggplot(aes(x = stem_length, y = stem_dry_mass, colour = watershed)) +\n  geom_point()\n\nshape_plot &lt;- plant_task_clean_data %&gt;%\n  ggplot(aes(x = stem_length, y = stem_dry_mass, shape = watershed)) +\n  geom_point()\n\ncowplot::plot_grid(color_plot, shape_plot, ncol = 1, align = \"v\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Descriptive Stats</span>"
    ]
  },
  {
    "objectID": "week4_descriptive_stats.html#tweaking-plots",
    "href": "week4_descriptive_stats.html#tweaking-plots",
    "title": "4¬† Descriptive Stats",
    "section": "Tweaking plots",
    "text": "Tweaking plots\nTo make your figures publication ready, here are some advice on changing the labels, adding colour, changing the shape and size, plotting multiple plots.\n\nThemesLabels and titlesShapes, colours, and sizeSplitting plots\n\n\nggplot has some default themes you can use for your figures instead of manually changing each feature. Here is what the themes look like when you apply them.\n\n\n\nTo add a labels independently for the title using ggtitle(), subtitle using ggsubtitle(), x-axis label using xlab(), y-axis label using ylab(), or all within the labs() function as shown here:\n\nplant_task_clean_data %&gt;%\n  ggplot(aes(x = watershed, y = stem_length)) +\n  geom_boxplot() +\n  # Modify here\n  labs(title = \"Your title\",\n       subtitle = \"your subtile\",\n       x = \"Treatment\", \n       #x = NULL, # You can also remove labels by calling NULL\n       y = \"Stem length (mm)\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nMore options can be found here such as changing the size and colour of the text, or spliting long titles into multiple lines.\n\n\nTo manually change the point shapes, use the scale_shape_manual() function, and choose the shape with it‚Äôs associated number. More options such as shape size can be found here.\n\n\nplant_task_clean_data %&gt;%\n  ggplot(aes(x = stem_length, y = stem_dry_mass, shape = watershed)) +\n  geom_point() +\n  # Modify here\n  scale_shape_manual(values = c(4, 15))+\n  labs(x = \"Stem length (mm)\", \n       y = \"Stem dry mass (g)\",\n       shape = \"Watershed\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nThere is a vast number of R libraries that that are tailored to create pretty palettes. You can explore them in your own time. Here is an R package called colorspace which I like to use often.\nYou can change the outline or fill colour overall or by groups (e.g.¬†watershed) with either method below. Note, you can either use existing R base colour like tomato1, specific R package color names, or hex values (e.g.¬†#000000 for black) for very specific colours.\n\nsingle_colour &lt;- plant_task_clean_data %&gt;%\n  ggplot(aes(x = watershed, y = stem_length)) +\n  geom_boxplot(colour = \"darkred\") + # Modify here\n  labs(subtitle = \"Change a single outline colour\",\n       x = \"Treatment\", \n       y = \"Stem length (mm)\") +\n  theme_classic()\n\nsingle_fill &lt;- plant_task_clean_data %&gt;%\n  ggplot(aes(x = watershed, y = stem_length)) +\n  geom_boxplot(fill = \"#F5C4B8\") + # Modify here\n  labs(subtitle = \"Change a single fill colour\",\n       x = \"Treatment\", \n       y = \"Stem length (mm)\") +\n  theme_classic()\n\ngroup_colour &lt;- plant_task_clean_data %&gt;%\n  ggplot(aes(x = watershed, y = stem_length, colour = watershed)) + # Modify here\n  geom_boxplot() +\n  # Modify here\n  scale_color_manual(values = c(\"darkblue\", \"darkred\")) +\n  labs(subtitle = \"Change outline colour by group\",\n       x = \"Treatment\", \n       y = \"Stem length (mm)\",\n       colour = \"Watershed\") +\n  theme_classic()\n\ngroup_fill &lt;- plant_task_clean_data %&gt;%\n  ggplot(aes(x = watershed, y = stem_length, fill = watershed)) + # Modify here\n  geom_boxplot() +\n  # Modify here\n  scale_fill_manual(values = c(\"#B8CEF5\", \"#F5C4B8\")) +\n  labs(subtitle = \"Change fill colour by group\",\n       x = \"Treatment\", \n       y = \"Stem length (mm)\",\n       fill = \"Watershed\") +\n  theme_classic()\n\ncowplot::plot_grid(single_colour, single_fill, \n                   group_colour, group_fill, ncol = 2, align = \"v\")\n\n\n\n\n\n\n\n\nYou can also colour by gradient if the colour values are continuous. Here is an example with a scatter plot.\n\ncat_plot &lt;- plant_task_clean_data %&gt;%\n  ggplot(aes(x = stem_length, y = stem_dry_mass, colour = watershed)) +\n  geom_point() +\n  # Modify here\n  scale_colour_manual(values = c(\"#B8CEF5\", \"#F5C4B8\")) +\n  labs(subtitle = \"Fill by categorical group\",\n       x = \"Stem length (mm)\", \n       y = \"Stem dry mass (g)\",\n       colour = \"Watershed\") +\n  theme_classic()\n\n\ncon_plot &lt;- plant_task_clean_data %&gt;%\n  ggplot(aes(x = stem_length, y = stem_dry_mass, colour = leaf_dry_mass)) +\n  geom_point() +\n    labs(subtitle = \"Fill by continuous value\",\n       x = \"Stem length (mm)\", \n       y = \"Stem dry mass (g)\",\n       colour = \"Leaf dry mass (g)\") +\n  theme_classic()\n\ncowplot::plot_grid(cat_plot, con_plot, ncol = 1, align = \"v\")\n\n\n\n\n\n\n\n\n\n\nThe facet approach partitions a plot into a matrix of panels. Each panel shows a different subset of the data. Let‚Äôs seperate out plant_task_clean_data by year using the facet_grid() function.\n\n# Split in vertical direction\nplant_task_clean_data %&gt;%\n  ggplot(aes(x = stem_length, y = stem_dry_mass, colour = watershed)) +\n  geom_point() +\n  scale_colour_manual(values = c(\"#B8CEF5\", \"#F5C4B8\")) +\n  labs(x = \"Stem length (mm)\", \n       y = \"Stem dry mass (g)\",\n       colour = \"Watershed\") + \n  theme_classic() +\n  # Modify here\n  facet_grid(year ~ .)\n\n\n\n\n\n\n\n# Split in horizontal direction\nplant_task_clean_data %&gt;%\n  ggplot(aes(x = stem_length, y = stem_dry_mass, colour = watershed)) +\n  geom_point() +\n  scale_colour_manual(values = c(\"#B8CEF5\", \"#F5C4B8\")) +\n  labs(x = \"Stem length (mm)\", \n       y = \"Stem dry mass (g)\",\n       colour = \"Watershed\") + \n  theme_classic() +\n  # Modify here\n  facet_grid(. ~ year)\n\n\n\n\n\n\n\n\nFacets can be placed side by side using the function facet_wrap() as followed. Here, we switch to have the years coloured and the plot split by watershed. How you decide which variable to split and colour will depend on your story and hypothesis.\n\nplant_task_clean_data %&gt;%\n  ggplot(aes(x = stem_length, y = stem_dry_mass, colour = factor(year))) +\n  geom_point() +\n  scale_colour_manual(values = c(\"#B8CEF5\", \"#F5C4B8\")) +\n  labs(x = \"Stem length (mm)\", \n       y = \"Stem dry mass (g)\",\n       colour = \"Watershed\") + \n  theme_classic() +\n  # Modify here\n  facet_wrap(~ watershed)\n\n\n\n\n\n\n\n\nIf you have different types of plots you would like to join together, the R package cowplot does a good job of this. More details on cowplot can be found here, but here is a taste of how to use cowplot. The figure legends are position at the bottom to look nicer using theme(legend.position=\"bottom\").\n\ncowplot::plot_grid(group_fill + theme(legend.position = \"bottom\"), \n                   cat_plot + theme(legend.position = \"bottom\"), \n                   ncol = 2, align = \"v\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Descriptive Stats</span>"
    ]
  },
  {
    "objectID": "week4_descriptive_stats.html#for-the-adventurous-folks",
    "href": "week4_descriptive_stats.html#for-the-adventurous-folks",
    "title": "4¬† Descriptive Stats",
    "section": "For the adventurous folks",
    "text": "For the adventurous folks\nWe will use a new dataset provided by lterdatasampler, called pie_crab. The pie_crab contains body size data of Atlantic marsh fiddler crab (Minuca pugnax) across various salt marshes throughout the eastern coast of the United States to test the Bergmann‚Äôs rule, which predicts that organisms at higher latitudes are larger than ones at lower latitudes.\n\n13 marshes were sampled on the Atlantic coast of the United States in summer 2016, spanning &gt; 12 degrees of latitude, from northeast Florida to northeast Massachusetts. Between 25 and 37 adult male fiddler crabs were collected, and their sizes recorded, from each marsh between 2016-07-24 and 2016-08-13.\nHere is the metadata of the pie_crab data: - date: Date of collection - latitude: Latitude of the collection site in degrees - site: The site ID - size: Mean carapace width (mm) - air_temp: The mean air temperature of the day. - air_temp_sd: The standard deviation of the measured air temprature. Also an indicator of seasonality - water_temp - water_temp_sd - name: Names of the sampled Marshes.\n\n#install.packages(\"lterdatasampler\")\n\n# Load R package\nlibrary(lterdatasampler)\n\n# Load 'pie_crab' from the R package\nglimpse(pie_crab)\n\nRows: 392\nColumns: 9\n$ date          &lt;date&gt; 2016-07-24, 2016-07-24, 2016-07-24, 2016-07-24, 2016-07‚Ä¶\n$ latitude      &lt;dbl&gt; 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, ‚Ä¶\n$ site          &lt;chr&gt; \"GTM\", \"GTM\", \"GTM\", \"GTM\", \"GTM\", \"GTM\", \"GTM\", \"GTM\", ‚Ä¶\n$ size          &lt;dbl&gt; 12.43, 14.18, 14.52, 12.94, 12.45, 12.99, 10.32, 11.19, ‚Ä¶\n$ air_temp      &lt;dbl&gt; 21.792, 21.792, 21.792, 21.792, 21.792, 21.792, 21.792, ‚Ä¶\n$ air_temp_sd   &lt;dbl&gt; 6.391, 6.391, 6.391, 6.391, 6.391, 6.391, 6.391, 6.391, ‚Ä¶\n$ water_temp    &lt;dbl&gt; 24.502, 24.502, 24.502, 24.502, 24.502, 24.502, 24.502, ‚Ä¶\n$ water_temp_sd &lt;dbl&gt; 6.121, 6.121, 6.121, 6.121, 6.121, 6.121, 6.121, 6.121, ‚Ä¶\n$ name          &lt;chr&gt; \"Guana Tolomoto Matanzas NERR\", \"Guana Tolomoto Matanzas‚Ä¶\n\n\n1. Do a data quality check\n\nAny missing data?\nAre there duplicates?\nCheck the data structure and types and correct any mistakes\nCheck the data distribution carapace size. Are there outliers?\n\n2. Calculate the central tendency, spread, and sample size of the carapace size size by site and latitude\n\nDecide on calculations of central tendency and spread you will apply based on the distribution observed.\nWhich site has the highest average carapace size?\nWhich site has the lowest sample size?\n\n3. Plot the relationship between latitude and mean carapace width (plus raw carapace width) to test the Bergmann‚Äôs rule in Fidler crabs\n\nMake a publication ready figure (include colour).\nWhat relationship can you see?",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Descriptive Stats</span>"
    ]
  },
  {
    "objectID": "week4_descriptive_stats.html#time-series",
    "href": "week4_descriptive_stats.html#time-series",
    "title": "4¬† Descriptive Stats",
    "section": "Time series",
    "text": "Time series\nMany of you might be working with environmental data (e.g.¬†soil or air temperatures and humidity) collected from deployed data loggers. While, you may not not use the whole time series dataset for your study, it could useful to visualise the study period and highlight where you took your samples (e.g.¬†using geom_vline().\nHere is a dataset called winter_clim_dat.csv that includes outside (EXT) and inside (DEEP) cave air temperature and humidity of two sites (MAM, YES). Using everything we learnt today, you can create a figure like this using the geom_line() function and separating temperature and humidity by location (EXT, DEEP) and site (MAM, YES).\nThe code below also includes ways of converting raw date values into meaningful values that R can interpret correctly (with as.POSIXct() function). The link also discusses ways of dealing with missing and weird time series data.\n\nclim_raw &lt;- read_csv(\"https://raw.githubusercontent.com/nicholaswunz/ECS200-Workshop/refs/heads/main/data/winter_clim_dat.csv\") %&gt;%\n  dplyr::mutate(date_time = as.POSIXct(date_time, format = \"%d/%m/%Y %H:%M\"), # convert character to date and time\n                DOY       = as.POSIXlt(date_time)$yday, # calculate day of the year\n                month     = format(as.Date(date_time, format = \"%m/%d/%Y\"),\"%m\"), # month as numeric\n                month_cat = format(as.Date(date_time, format = \"%m/%d/%Y\"),\"%B\"), # month as name\n                location =  factor(location, levels = c('EXT', 'DEEP')))  \n\ntemp_plot &lt;- clim_raw %&gt;% \n  ggplot() +\n  geom_line(aes(x = date_time, y = air_temp, colour = location)) +\n  scale_colour_manual(values = c(\"#F5C4B8\", \"darkred\")) + # manually change colour\n  geom_vline(xintercept = as.POSIXct(as.Date(\"2023-07-10\")), # add horizontal line when data were sampled\n                                     linetype = \"dashed\") + \n  geom_vline(xintercept = as.POSIXct(as.Date(\"2023-08-12\")),\n                                     linetype = \"dashed\") + \n  labs(x = \"Date\", \n       y = \"Air temperature (¬∞C)\") + \n  theme_classic() +\n  facet_wrap(~ site) # separate by site\n\n\nRH_plot &lt;- clim_raw %&gt;% \n  ggplot() +\n  geom_line(aes(x = date_time, y = RH, colour = location)) +\n  scale_colour_manual(values = c(\"#B8CEF5\", \"darkblue\")) + # manually change colour\n    geom_vline(xintercept = as.POSIXct(as.Date(\"2023-07-10\")), # add horizontal line when data were sampled\n                                     linetype = \"dashed\") + \n  geom_vline(xintercept = as.POSIXct(as.Date(\"2023-08-12\")),\n                                     linetype = \"dashed\") + \n  labs(x = \"Date\", \n       y = \"Relative humidity (%)\") + \n  theme_classic() +\n  facet_wrap(~ site) # separate by site\n  \ncowplot::plot_grid(temp_plot, \n                   RH_plot, \n                   ncol = 1, align = \"v\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Descriptive Stats</span>"
    ]
  },
  {
    "objectID": "week4_descriptive_stats.html#beautify-figures",
    "href": "week4_descriptive_stats.html#beautify-figures",
    "title": "4¬† Descriptive Stats",
    "section": "Beautify figures",
    "text": "Beautify figures\nIf you want to go beyond what we learnt and further enhance your figure production skills, here is a link that provides a tutorial to convert default ggplots to publication ready plots including this one on histograms .",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Descriptive Stats</span>"
    ]
  },
  {
    "objectID": "week4_descriptive_stats.html#additional-resource",
    "href": "week4_descriptive_stats.html#additional-resource",
    "title": "4¬† Descriptive Stats",
    "section": "Additional resource",
    "text": "Additional resource\n\nMore detail on levels of measurements: norminal, ordinal, interval and ratio.\nggplot2 Essentials has all the guide for creating the most common types of graphs from bar and line plots, to pie charts.\nA collection of R chart examples with example code to create them.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Descriptive Stats</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Farkas, K. R., Brown, Z. A., King, J. L., Nicotra, A. B., Head,\nM. L. and Arnold, P. A. (2025). Combined heat and drought\naffect the abundance, composition and diversity of subalpine\nsurface-active soil arthropod communities. Ecological\nEntomology.\n\n\nJuice, S. M., Fahey, T. J., Siccama, T. G., Driscoll, C. T.,\nDenny, E. G., Eagar, C., Cleavitt, N. L., Minocha, R. and Richardson, A.\nD. (2006). Response\nof sugar maple to calcium addition to northern hardwood forest.\nEcology 87, 1267‚Äì1280.\n\n\nPeters, S. C., Blum, J. D., Driscoll, C. T. and Likens, G.\nE. (2004). Dissolution\nof wollastonite during the experimental manipulation of hubbard brook\nwatershed 1. Biogeochemistry 67, 309‚Äì329.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "the_islands.html",
    "href": "the_islands.html",
    "title": "The Islands",
    "section": "",
    "text": "Design your project\nThe Island is a virtual environment where the original intention was for students to collect data for addressing questions in epidemiology. However, the Island has since been updated to include field stations that allow for plant growth. The plants can represent any plant, either an agriculturally significant plant, an indigenous significant plant, or a species of conservation concern. You decide on what plant it is and how it related to your topic.\nNote, the plants grow in real time, and typically take 14 days to fully grow, depending on the local climate.\nAccess The Island from myMurdoch Learning.\nThere are three islands of focus (Fig. 1):\nAltogether, there are three field stations from three islands with differing climates. Each station has 36 plots.\nYou can manipulate Nitrogen (N) and Phosphorus (P) levels in the soil prior to growing the plants. The level of N and P are represented by blacks. Two blocks are the default, so we would consider them normal levels (Fig. 2), no blocks mean no N or P, four blocks means twice the concentration of normal levels, and five blocks is the maximum allowed (represents 2.5 times normal levels). Give the blocks some values. Use realistic values based on the literature and what is considered normal for the plant of interest.\nBecause there are three stations that span across different climates. You can compare the effect of temperature or rainfall on plant growth, fruit production etc. All stations provide the date, maximum temperature in degrees Celsius and rainfall in millimetres (Table 1). You can use this data to correlate with your dependent variables. You have the option to look at the interaction of N or P with temperature or rainfall (factorial design).\nFor the 36 plots per site, it means you can have 18 replicate plots/treatment if you have two treatments, 12 replicate plots/treatment if you have three treatments, 9 replicate plots/treatment if you have four treatments, and 6 replicate plots/treatment if you have five treatments. Balance between number of treatments and number of replicates.",
    "crumbs": [
      "The Islands"
    ]
  },
  {
    "objectID": "the_islands.html#design-your-project",
    "href": "the_islands.html#design-your-project",
    "title": "The Islands",
    "section": "",
    "text": "Fig. 2. Example nitrogen (N) or phosphorus (P) block manipulation, where no blocks mean no N or P, two blocks is the default/normal N or P levels, four blocks means twice the concentration of normal levels, and five blocks is the maximum allowed (represents 2.5 times normal levels).\n\n\n\n\nTable 1: Example table output from the Kennedy Climate Station on Providence Island. Date is based on the simulation and presented by day, Max Temp is the maximum temperature (¬∞C) recorded on the day, and Rainfall is the cumulative rainfall of the day (mm).\n\n\nDate\nMax Temp (¬∞C)\nRainfall (mm)\n\n\n\n\n01/064\n18.8\n1.0\n\n\n02/064\n23.7\n0.8\n\n\n03/064\n25.3\n0.8\n\n\n04/064\n29.3\n0.0\n\n\n05/064\n29.7\n14.1\n\n\n\n\n\nWhat you can measure?\nYour plant will look like this (Fig. 3). The green parts represent leaves, the purple circles represent fruits, and the white circles represent flowers. You can measure the following as response dependent variables:\n\n\n\nFig. 3. Example plant after 10 days since germination.\n\n\nHeight: You can use a ruler to measure on your screen.\nGrowth rate: If you measure height over time, you can calculate growth rate. Note, make sure your screen is the same size to ensure consistency in your measurements over time.\nNumber of leaves: Count the number of green parts.\nNumber of fruits: Count the number of purple circles.\nNumber of flowers: Count the number of white spots.\nBranches: Count the number of diverging branches from the main stem.\nYield: Once harvested, you will get a number in the ‚ÄúHarvest‚Äù tab (Table 2). The data table will include Date of harvest, the row and column of the plot, and the yield or biomass (g). Once harvested, the plant doesn‚Äôt grow again (ONE time, destructive). So, be careful on when you plan to harvest the plant.\n\nTable 2: Example yield table output from Hofn Field Station on Ironbard. Date is based on the simulation and presented by day, Row and Column are the positon of the plant in the field grid, and Yield is total biomass value (g).\n\n\nDate\nRow\nColumn\nYield\n\n\n\n\n01/064\n1\n1\n320\n\n\n02/064\n1\n2\n269\n\n\n03/064\n1\n3\n327\n\n\n04/064\n1\n4\n390\n\n\n05/064\n1\n5\n307\n\n\n\nI have no idea what the red circles are. You can count them and assign a name to them if you like (e.g.¬†berries, fungal pathogen).",
    "crumbs": [
      "The Islands"
    ]
  }
]