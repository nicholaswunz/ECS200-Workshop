{
  "hash": "aa55417233dbdb3b88625ded95221804",
  "result": {
    "engine": "knitr",
    "markdown": "# Quality Check\n\n**Week 2** - Quality checks and data exploration\n\n\n>All statistical techniques have in common the problem of â€˜*rubbish in, rubbish out*â€™\n\nIn this workshop, you will learn how to check the quality of the raw data you imported, and steps to correct errors in the raw data.\n\n![](images/base_tidy.png)\n\n## Background reading {.unnumbered}\n\nHow do we know the data is ready for analysis? \nBefore we do any analysis, we need to check the raw data for the following:\n\n- **Check data structure and types**: Use `str()` and `summary()` to ensure each column is the correct type (numeric, factor, character, etc.) and matches your expectations. e.g., Convert relevant character columns to factors for categorical analysis.\n- **Inspect for missing values**: Use `colSums(is.na()` or visual tools (e.g., `naniar::gg_miss_var()` or `visdat_viz_dat()`) to identify missing data and decide how to handle it.\n- **Check for duplicates**: Ensure there are no unintended duplicate rows or IDs.\n- **Validate categorical variables**: Confirm that categories are consistent and correctly formatted (e.g., all lower case, no extra spaces).\n- **Scan for outliers or impossible values**: Look for values outside expected ranges (e.g., negative stem lengths, impossible dates).\n- **Review column names**: Ensure column names are meaningful, have no spaces or special characters, and are consistent.\n- **Preview the data**: Use plotting functions to visually inspect the data for obvious issues.\n- **Check for extra rows or columns**: Sometimes, files have summary rows, notes, or empty columns that should be removed.\n\nThese steps help ensure your data is reliable, interpretable, and suitable for statistical analysis. Importantly, it makes you a trustworthy researcher!\n\n\n# Before we start {.unnumbered}\n\nClick **File > New File > R Script** to start. Write the workshop name, the main goal and your name and date. Always do this when starting a new script.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Week 1 workshop - Getting started\n# Getting familiar with R and load a file\n# Written by Nicholas Wu, 06/11/2024, Murdoch University\n```\n:::\n\n\n\n\n\n\n\n\n### Exercise (5 min) {.unnumbered}\n\nðŸ§ª **Get your workflow set up**\n\nNext, load your appropriate packages (the same `tidyverse`, and a one for visualising missing data called [`visdat`](https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html) at this stage), set your working directory via `setwd()`, and load the `plant_calcium.csv` via `read_csv()`. \n\nLets call the imported data object `plant_data.csv` this time.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Step 1: Data Quality Check {.unnumbered}\n\n## 1.1. Initial check {.unnumbered}\n\nThis helps you spot if variables are coded incorrectly (e.g., numbers as characters or vice versa), which could be due to the researcher error before inporting the data.\nSome example mistakes include:\n\n- **Incorrect data types**: Numeric columns may be read as character (text) if there are unexpected symbols, missing values coded inconsistently, or formatting issues (**e.g.** a column meant to be numbers may contain text or empty strings, causing R to treat it as character instead of numeric). \n- **Inconsistent coding**: Categorical variables may be inconsistently labeled (**e.g.**, \"Male\", \"male\", \"M\"), leading to multiple categories that should be merged.\n- **Header issues**: Sometimes, the header row is missing or duplicated, or extra non-data rows are included at the top or bottom of the file.\n- **Encoding problems**: Special characters (e.g., accents, non-English letters) may not display correctly if the file encoding is not specified or mismatched.\n- **Trailing spaces**: Spaces at the start or end of strings can create unexpected categories or prevent proper matching.\n\n![](images/check_initial.png)\n\n\nFor small datasets (like in this workshop) it is easier to make fixes directly from Excel and import the new .csv file.\nAs before, we will check the data here first with the `str()` function.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check the structure of your data\nstr(plant_data)\n\n# Get a summary of all variables\nsummary(plant_data)\n```\n:::\n\n\n\n\n\n\n\n\n### Exercise (5 min) {.unnumbered}\n\nðŸ§ª **Find the incorrect class in this dataset**\n\nI have created an example dataset called `fake_data` with three things wrong with it. \nFind the the three issues in this dataset.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfake_data <- data.frame(\n  site = c(\"A\", \"B\", \"C\", \"A\", \"B\", \"A\", \"B\", \"C\", \"a\", \"B\", \"A\", \"B\", \"A\", \"B\", \"C\", \"C\", \"B\", \"A\", \"A\", \"C\", \"B\", \"C\", \"C\", \"A\", \"A\", \"A\", \"A\", \"B\", \"C\", \"C\", \"C\"),\n  species_1 = c(7, 25, 30, 50, 38, 13, 5, 31, 34, 22, 41, 25, 22, 37, 39, 13, 45, 10, 40, 7, 28, 36, 19, 2, 12, 5, 16, 38, 27, 44, 44),\n  species_2 = c(9.3, 8.6, 0.8 , 7.5, 9 , 9.1, 4.3, 8.6, 0.1, 7.8, 1.2, 6.2, 0.4, 0.4, 7.4, 1.9, 8.3, 7.8, 2.9, 9.3, 9.1, 2.3, 6.3, 8.5, 6.5, 6.6, \"1,7\", 1.8, 8.4, 4.7, 4.7),\n  species_3 = c(190, 160, 70, 430, 310, 99, 530, 420, 371, 357, 198, 171, 463, 124, 254, 484, 435, 409, 122, 305, 410, 162, 473, 200, 401, 273, 421, 419, 293, 487, 487),\n  species_4 = c(2, 0, 4, 8, 6.7, 3, 7.2, 4.3, 2, NA, 10, 10, 6, 4, 8, 1.7, 1, 0, NA, 4, 6, 8.2, 10, 6, 2, 5, 10, 7, NA, NA, NA)\n)\n```\n:::\n\n\n\n\n\n\n\n\n\nWhat are the identified issues?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 1.2. Identify missing values {.unnumbered}\n\nMissing data may appear as blanks, \"NA\", \".\", or other placeholders. \nIf not handled properly, this can cause errors or misinterpretation during analysis.\n\n![](images/check_missing.png)\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check for missing values in each column\ncolSums(is.na(plant_data))\n\n# Visualise missing data pattern\nvisdat::vis_dat(plant_data)\n```\n:::\n\n\n\n\n\n\n\n\n`vis_dat()` visualises the whole dataframe at once, and provides information about the class of the data input into R, as well as whether the data is missing or not.\n\nThe function `vis_miss()` provides a summary of whether the data is missing or not. It also provides the amount of missings in each columns.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualise missing data pattern\nvisdat::vis_miss(plant_data)\n```\n:::\n\n\n\n\n\n\n\n\n**Option**: Removing columns with missing values\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Removes all rows with NA in the dataset\nplant_data_clean <- plant_data %>% \n  drop_na()\n\n# not recommended if NA is scattered across columns (e.g. leaf1area) because some important variables might be dropped out.\n\n# Drop rows where NA is present in the elevation column only.\nplant_data_clean <- plant_data %>% \n  drop_na(elevation)\n\n# Run the vis_miss again on the clean data to check if the NA rows are removed. \nvisdat::vis_miss(plant_data_clean)\n```\n:::\n\n\n\n\n\n\n\n\n### Exercise (5 min) {.unnumbered}\n\nðŸ§ª **Identify and handle missing values in the `fake_data` dataset**\n\n- Which column contains missing variables?\n- How many missing values are there?\n- Remove rows with missing values and create a new object called `fake_data_clean`.\n- Visualise the new `fake_data_clean` with `visdat::vis_dat(fake_data_clean)`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 1.3. Check for duplicates {.unnumbered}\n\n![](images/check_duplicate.png)\n\nThere are two common duplicate types that can happen in your dataset.\n\n1. **Row duplicates**: where the values and names of two rows are identical 99% of the time, this is user error (e.g. copy pasted). \nThese must be identified and removed.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(duplicated(plant_data))  # Returns the number of duplicate rows\n\n# View the duplicate rows themselves\nplant_data[duplicated(plant_data), ]\n```\n:::\n\n\n\n\n\n\n\nIn the `plant_data`, there are no row duplicates.\n\n2. **Value duplicates**: 90% of value duplicates in a column might be biologically realistic responses and is likely due to rounding of values during recording (e.g. values 2.5 and 2.5 might look duplicated due to user rounding. Actual values are 2.47 and 2.49). \nThis is usually okay and can be kept in the dataset. \nUser error occurs if there is a pattern in duplicates (e.g. **2**,**2**,6,1,**2**,**2**,9,4,**2**,**2**,5,9). \nThis can occur due to copy and pasting in the following row by accident.\n\nYou the researcher must decide whether these duplicate responses are real or due to user error.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(duplicated(plant_data$leaf_dry_mass))  # Returns the number of duplicate rows\n```\n:::\n\n\n\n\n\n\n\nIn the `leaf_dry_mass` column, there are 51 value duplicates.\n\n### Exercise (3 min) {.unnumbered}\n\nðŸ§ª **Identify the duplicate row in the `fake_data` dataset**\n\n- Where is the duplicate row?\n- Remove the duplicate row. Either manually in Excel (easy), or an R function (challenge).\n- Are there other duplicate values and do you know if they are ecologically relevant duplicates (similar response) or user error?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Step 2: Visualising Data {.unnumbered}\n\n## 2.1 Check for outliers {.unnumbered}\n\nOutliers aren't inherently \"bad,\" but they can cause problems depending on the context and goals of your analysis. \nThey can:\n\n1. **Skew statistical results**: A single extreme value can pull the mean far from the center, increase variability making data seem more spread than it really us, and can distrort the slope and intercept of linear models, leading to misleading predictions.\n2. **Create obscure patterns**: Hide clusters or trends that would otherwise be visible.\n3. **Indicate user error**: Data entry mistakes (e.g., typing 1000 instead of 100), measurement errors (e.g., faulty sensors), incorrect data merging (e.g., mixing units like metres and feet).\n\nThere are different ways we can check for outliers. See a more comprehensive [page](https://statsandr.com/blog/outliers-detection-in-r/) for more options. \nHere, we will create two common plots to check for outliers, and run some simple methods for detecting and removing outliers.\n\n### Boxplot {.unnumbered}\n\nWe can use the `ggplot()` function from the [`ggplot`](https://www.sthda.com/english/wiki/ggplot2-essentials) package to create a boxplot via `geom_boxplot()` showing the distribution of the `lead2area` data.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplot of leaf2area to detect potential outliers\nggplot(plant_data, aes(y = leaf2area)) +\n  geom_boxplot(fill = \"lightgrey\") +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 117 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week2_data_exploration_files/figure-html/boxplot-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n### Histogram {.unnumbered}\n\nAnother way we can visualise outliers is with histograms via `geom_histogram()` or density plots via [`geom_density()`](https://www.sthda.com/english/wiki/ggplot2-density-plot-quick-start-guide-r-software-and-data-visualization)\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplot of height to detect potential outliers\nggplot(plant_data, aes(x = leaf2area)) +\n  geom_histogram() +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 117 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week2_data_exploration_files/figure-html/hist-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\nHere you can see one clear outlier with a value above 100. All other values are below 25.\nYou can either manually remove the outlier on Excel, or with the following code below.\n\n**Option**: Remove outliers using the interquartile range (IQR) rule.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# View potential outliers using IQR rule\nQ1 <- quantile(plant_data$leaf2area, 0.25, na.rm = TRUE)\nQ3 <- quantile(plant_data$leaf2area, 0.75, na.rm = TRUE)\nIQR <- Q3 - Q1\n\n# Filter rows with height outside 1.5 * IQR range\noutliers <- filter(plant, height < (Q1 - 1.5 * IQR) | height > (Q3 + 1.5 * IQR))\noutliers\n```\n:::\n\n\n\n\n\n\n\n\n\n:::{.callout-note}\n\n## Note\nDon't just blindly remove outliers! \n\n:::\n\nMake sure the numbers are biologically realistic based on intuition and comparing with the literature.\nIf the values are unrealistic, it is a safe assumption to remove them.\n\n## 2.2 Is the data normally distributed {.unnumbered}\n\nThis step is required to check if the data is suitable for certain types of analysis.\nSometimes, [transformation](week3_tidy_data.qmd) is required for certain data to meet the assumptions of certain statistical methods and improve the interpretability and performance of models.\nMany statistical techniquesâ€”like linear regression, ANOVA, and t-testsâ€”assume that the data is normally distributed, has constant variance, and is linearly related (from your [MAS183 - Statistical Data Analysis](https://handbook.murdoch.edu.au/units/18/MAS183) and [MAS224 - Biostatistical Methods](https://handbook.murdoch.edu.au/units/02/mas224) units).\nIf the data is skewed, has outliers, or shows non-constant variance (heteroscedasticity), these assumptions are violated, which can lead to **biased estimates, incorrect conclusions, or poor model fit**.\n\nBy applying transformations such as logarithmic, square root, or Box-Cox, we can:\n\n- **Reduce skewness** and make the distribution more symmetrical.\n- **Stabilise variance** across levels of an independent variable.\n- **Improve linearity** between variables.\n- **Minimise the influence of outliers**.\n\n\nLet's check the distribution of `leaf2area` after removing that one outlier.\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n # remove values above 100\nplant_data_clean <- plant_data %>%\n  filter(leaf2area < 100)\n\nggplot(plant_data_clean, aes(x = leaf2area)) +\n  geom_histogram() +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week2_data_exploration_files/figure-html/normal-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\nLooks normally distributed to me! We will learn data transformation in next weeks workshop.\n\n\n# Homework {.unnumbered}\n\nWe will use a modified `plant_calcium.csv` dataset called `plant_calcium_homework.csv` for the next workshop. \nHere, you need to conduct a quality check and data exploration of this new dataset and fix any potential issues.\n\nTo make it a bit easier for you, I have given you hints where the errors are so you dont have to look through every single column or every problem.\nBut in your own dataset, you will need to thoroughly check your own data in the future. \n\nHints:\n\n1. Identify **missing values** in one of the numeric columns. Remember to check if you really need to remove these missing value rows or not. \n2. There is an **inconsistent coding** in one of the categorical variables. Correct the incorrect coding. You can do this on Excel, or from R (see adventurous folks section)\n3. There are **two numeric columns** with outliers. One is biologically realistic, the other one is a data entry mistake. Decide which one is the data entry mistake and remove/correct that outlier.\n4. Create a **clean version** of the data after removing the errors as `plant_homework_data_clean` and **visualise** one of the numeric columns as a density plot.\n\nRemember to create a header with the next workshop titled \"Week 3 workshop - Tidying data\", a description called \"Tidy data through transformation and filtering\", your name, and the next workshops date.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## For the adventurous folks {.unnumbered}\n\nHere we will start thinking about writing code efficiently.\nFor example, you would have noticed by now that whatever raw data we load in R, any categorical columns are automatically listed as characters. \nSo you can write a code that both loads the data and change the characters to factors in the same line of code (e.g. using the `dplyr::mutate()` function).\nLoad the `plant_calcium_homework.csv` and change categorical variables from character and factor.\n\nRepeat the same homework as above, but instead of correcting the errors by editing them on Excel, do all the corrections within the R environment. Visualise the **clean version** of the the data with a density plot but separate the density by the treatment groups (reference and W1 variables). \n\n\n# Extra Stuff {.unnumbered}\n\n## Why is my code not working! {.unnumbered}\n\nComputers are only as smart as the humans that use them.\n\nIf your code is not working there is most likely a spelling mistake or a typographic error. These human errors are easy to miss but equally easy to fix!\n\nIf your code is not working take a moment to breathe. Then check for common, minor errors such as:\n\n- Spelling mistakes\n- Wrong dataset name\n- Wrong variable (column) name\n- Missing or wrong quotation mark\n- Missing bracket\n- Inconsistent cases (e.g. Uppercase)\n- Missed a step\n- Invalid syntax (e.g. spaces)\n- Duplicates of the same function with multiple errors â€“ keep your scripts tidy!\n- These reading/typing mistakes are the majority of encountered errors. They are not a big deal and are easily corrected.\n\nYou can and should easily fix the above mistakes yourself!\nWe want you to know how to work problems out independently.\n\n\n### Exercise {.unnumbered}\n\nðŸ§ª **Why does this code not work?**\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_variable <- 10\nmy_varÄ±able\n#> Error: object 'my_varÄ±able' not found\n```\n:::\n\n\n\n\n\n\n\n\nLook carefully! (This may seem like an exercise in pointlessness, but training your brain to notice even the tiniest difference will pay off when programming.)\n\n\n## Additional resource {.unnumbered}\n\n- How to [rename factor levels](https://www.r-bloggers.com/2024/03/title-how-to-rename-factor-levels-in-r-with-examples/) in R.\n- CrashCourse Statistics video on [Plots, Outliers, and Justin Timberlake](https://youtu.be/HMkllhBI91Y?si=B2oEhfrOjoaVPWyD), with examples of went to remove outliers.\n\n\n",
    "supporting": [
      "week2_data_exploration_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}